#!/usr/bin/env python3
"""
Alert Collection Agent
Autonomous alert collection system that gathers alerts from all ZmartBot alert servers,
processes them with RiskMetric and Cryptometer data, stores in Supabase, and prepares
professional MDC documentation for delivery to ZmartBot Master Agent.
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import aiohttp
import sqlite3
from collections import defaultdict, deque

# Add current directory to Python path
current_dir = Path(__file__).parent.parent.parent
sys.path.append(str(current_dir))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class AlertData:
    """Structured alert data"""
    alert_id: str
    symbol: str
    alert_type: str
    source_server: str
    timestamp: datetime
    timeframe: str
    signal_strength: float
    confidence_score: float
    technical_data: Dict[str, Any]
    riskmetric_data: Optional[Dict[str, Any]]
    cryptometer_data: Optional[Dict[str, Any]]
    market_conditions: Dict[str, Any]
    action_recommendation: str
    priority_level: str
    status: str

@dataclass
class AlertReport:
    """Professional alert report with MDC documentation"""
    symbol: str
    alert_summary: str
    technical_analysis: str
    risk_assessment: str
    market_context: str
    action_plan: str
    confidence_rating: str
    mdc_content: str
    created_at: datetime
    data_sources: List[str]

class AlertCollectionAgent:
    """
    Autonomous Alert Collection Agent

    Features:
    - Collects alerts from all ZmartBot alert servers
    - Integrates RiskMetric and Cryptometer data
    - Stores alerts in Supabase database
    - Generates professional MDC documentation
    - Maintains at least 1 alert per symbol
    - Autonomous operation with intelligent filtering
    - Manus integration for extraordinary alerts
    """

    def __init__(self, config_path: str = "alert_agent_config.json"):
        self.config = self._load_config(config_path)
        self.db_path = Path("data/alert_collection_agent.db")
        self.db_path.parent.mkdir(exist_ok=True)

        # Alert servers configuration
        self.alert_servers = {
            'whale_alerts': {'port': 8018, 'endpoint': '/whale-alerts'},
            'messi_alerts': {'port': 8014, 'endpoint': '/messi-alerts'},
            'live_alerts': {'port': 8017, 'endpoint': '/live-alerts'},
            'maradona_alerts': {'port': 8019, 'endpoint': '/maradona-alerts'},
            'pele_alerts': {'port': 8020, 'endpoint': '/pele-alerts'}
        }

        # Data sources
        self.riskmetric_agent = None
        self.cryptometer_system = None
        self.manus_client = None

        # Alert storage and processing
        self.alert_queue = deque(maxlen=1000)
        self.symbol_alerts_db = defaultdict(list)
        self.processed_alerts = {}

        # Performance tracking
        self.stats = {
            'alerts_collected': 0,
            'alerts_processed': 0,
            'reports_generated': 0,
            'manus_reports': 0,
            'symbols_covered': 0,
            'last_collection': None,
            'last_supabase_sync': None
        }

        # Initialize database
        self._init_database()

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load agent configuration"""
        default_config = {
            'collection_interval_minutes': 5,
            'min_confidence_threshold': 0.7,
            'high_priority_threshold': 0.85,
            'manus_threshold': 0.9,
            'max_alerts_per_symbol': 10,
            'alert_expiry_hours': 24,
            'enable_manus_integration': True,
            'enable_supabase_sync': True,
            'autonomous_mode': True
        }

        try:
            if Path(config_path).exists():
                with open(config_path, 'r') as f:
                    config = json.load(f)
                    return {**default_config, **config}
        except Exception as e:
            logger.warning(f"Could not load config from {config_path}: {e}")

        return default_config

    def _init_database(self):
        """Initialize SQLite database for alert storage"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS collected_alerts (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        alert_id TEXT UNIQUE NOT NULL,
                        symbol TEXT NOT NULL,
                        alert_type TEXT NOT NULL,
                        source_server TEXT NOT NULL,
                        timestamp TIMESTAMP NOT NULL,
                        timeframe TEXT,
                        signal_strength REAL,
                        confidence_score REAL,
                        technical_data TEXT,
                        riskmetric_data TEXT,
                        cryptometer_data TEXT,
                        market_conditions TEXT,
                        action_recommendation TEXT,
                        priority_level TEXT,
                        status TEXT DEFAULT 'pending',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')

                conn.execute('''
                    CREATE TABLE IF NOT EXISTS alert_reports (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        symbol TEXT NOT NULL,
                        alert_summary TEXT NOT NULL,
                        technical_analysis TEXT,
                        risk_assessment TEXT,
                        market_context TEXT,
                        action_plan TEXT,
                        confidence_rating TEXT,
                        mdc_content TEXT,
                        data_sources TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        is_active BOOLEAN DEFAULT 1,
                        UNIQUE(symbol, created_at)
                    )
                ''')

                conn.execute('''
                    CREATE TABLE IF NOT EXISTS symbol_coverage (
                        symbol TEXT PRIMARY KEY,
                        last_alert_time TIMESTAMP,
                        alert_count INTEGER DEFAULT 0,
                        best_alert_confidence REAL DEFAULT 0,
                        status TEXT DEFAULT 'needs_alert'
                    )
                ''')

                conn.execute('''
                    CREATE TABLE IF NOT EXISTS agent_stats (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        alerts_collected INTEGER,
                        alerts_processed INTEGER,
                        reports_generated INTEGER,
                        manus_reports INTEGER,
                        symbols_covered INTEGER,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')

                logger.info("âœ… Alert Collection Agent database initialized")

        except Exception as e:
            logger.error(f"âŒ Error initializing database: {e}")

    async def start_autonomous_collection(self):
        """Start autonomous alert collection cycle"""
        logger.info("ðŸ¤– Starting Alert Collection Agent (autonomous mode)")

        while self.config['autonomous_mode']:
            try:
                # Collect alerts from all servers
                await self._collect_all_alerts()

                # Process alerts with additional data
                await self._process_alerts_with_data()

                # Generate reports for symbols needing alerts
                await self._ensure_symbol_coverage()

                # Sync to Supabase
                if self.config['enable_supabase_sync']:
                    await self._sync_to_supabase()

                # Update statistics
                self._update_stats()

                # Log status
                logger.info(f"ðŸ“Š Collection cycle complete: {self.stats['alerts_collected']} alerts, "
                          f"{self.stats['symbols_covered']} symbols covered")

                # Wait for next collection cycle
                await asyncio.sleep(self.config['collection_interval_minutes'] * 60)

            except Exception as e:
                logger.error(f"ðŸ’¥ Error in collection cycle: {e}")
                await asyncio.sleep(60)  # Wait 1 minute before retrying

    async def _collect_all_alerts(self):
        """Collect alerts from all configured alert servers"""
        logger.info("ðŸ”„ Collecting alerts from all servers...")

        tasks = []
        for server_name, server_config in self.alert_servers.items():
            task = self._collect_from_server(server_name, server_config)
            tasks.append(task)

        # Collect from all servers concurrently
        results = await asyncio.gather(*tasks, return_exceptions=True)

        total_alerts = 0
        for i, result in enumerate(results):
            server_name = list(self.alert_servers.keys())[i]
            if isinstance(result, Exception):
                logger.warning(f"âš ï¸ Failed to collect from {server_name}: {result}")
            else:
                total_alerts += result
                logger.info(f"âœ… Collected {result} alerts from {server_name}")

        self.stats['alerts_collected'] += total_alerts
        self.stats['last_collection'] = datetime.now()

        return total_alerts

    async def _collect_from_server(self, server_name: str, server_config: Dict[str, Any]) -> int:
        """Collect alerts from a specific server"""
        try:
            url = f"http://localhost:{server_config['port']}{server_config['endpoint']}"

            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=30) as response:
                    if response.status == 200:
                        alerts_data = await response.json()
                        return await self._process_server_alerts(server_name, alerts_data)
                    else:
                        logger.warning(f"Server {server_name} returned status {response.status}")
                        return 0

        except Exception as e:
            logger.warning(f"Could not connect to {server_name}: {e}")
            return 0

    async def _process_server_alerts(self, server_name: str, alerts_data: Dict[str, Any]) -> int:
        """Process alerts from server response"""
        try:
            alerts = alerts_data.get('alerts', [])
            processed_count = 0

            for alert_raw in alerts:
                # Create structured alert data
                alert_id = f"{server_name}_{alert_raw.get('symbol', 'unknown')}_{int(datetime.now().timestamp())}"

                alert = AlertData(
                    alert_id=alert_id,
                    symbol=alert_raw.get('symbol', '').upper(),
                    alert_type=alert_raw.get('type', 'unknown'),
                    source_server=server_name,
                    timestamp=datetime.now(),
                    timeframe=alert_raw.get('timeframe', '1h'),
                    signal_strength=float(alert_raw.get('signal_strength', 0.5)),
                    confidence_score=float(alert_raw.get('confidence', 0.5)),
                    technical_data=alert_raw.get('technical_data', {}),
                    riskmetric_data=None,  # Will be populated later
                    cryptometer_data=None,  # Will be populated later
                    market_conditions=alert_raw.get('market_conditions', {}),
                    action_recommendation=alert_raw.get('action', 'monitor'),
                    priority_level=self._determine_priority(float(alert_raw.get('confidence', 0.5))),
                    status='collected'
                )

                # Filter by confidence threshold
                if alert.confidence_score >= self.config['min_confidence_threshold']:
                    self.alert_queue.append(alert)
                    processed_count += 1

            return processed_count

        except Exception as e:
            logger.error(f"Error processing alerts from {server_name}: {e}")
            return 0

    def _determine_priority(self, confidence: float) -> str:
        """Determine alert priority based on confidence score"""
        if confidence >= self.config['manus_threshold']:
            return 'extraordinary'
        elif confidence >= self.config['high_priority_threshold']:
            return 'high'
        elif confidence >= self.config['min_confidence_threshold']:
            return 'medium'
        else:
            return 'low'

    async def _process_alerts_with_data(self):
        """Process collected alerts with RiskMetric and Cryptometer data"""
        if not self.alert_queue:
            return

        logger.info(f"ðŸ” Processing {len(self.alert_queue)} alerts with additional data...")

        processed_alerts = []

        while self.alert_queue:
            alert = self.alert_queue.popleft()

            try:
                # Enhance with RiskMetric data
                alert.riskmetric_data = await self._get_riskmetric_data(alert.symbol)

                # Enhance with Cryptometer data
                alert.cryptometer_data = await self._get_cryptometer_data(alert.symbol)

                # Store in database
                await self._store_alert(alert)

                # Add to symbol alerts
                self.symbol_alerts_db[alert.symbol].append(alert)

                # Keep only the best alerts per symbol
                self._trim_symbol_alerts(alert.symbol)

                processed_alerts.append(alert)
                self.stats['alerts_processed'] += 1

            except Exception as e:
                logger.error(f"Error processing alert {alert.alert_id}: {e}")

        # Generate extraordinary reports for high-scoring alerts
        for alert in processed_alerts:
            if alert.priority_level == 'extraordinary' and self.config['enable_manus_integration']:
                await self._generate_manus_report(alert)

    async def _get_riskmetric_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        """Get RiskMetric data for symbol"""
        try:
            # Import RiskMetric agent
            from services.autonomous_riskmetric_agent import get_autonomous_riskmetric_agent

            agent = get_autonomous_riskmetric_agent()
            risk_data = await agent.get_symbol_risk_assessment(symbol)

            return risk_data

        except Exception as e:
            logger.warning(f"Could not get RiskMetric data for {symbol}: {e}")
            return None

    async def _get_cryptometer_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        """Get Cryptometer data for symbol"""
        try:
            # Load from autonomous cryptometer data
            data_file = Path(f"extracted_cryptometer_data/{symbol}_cryptometer_data.json")

            if data_file.exists():
                with open(data_file, 'r') as f:
                    cryptometer_data = json.load(f)
                return cryptometer_data

        except Exception as e:
            logger.warning(f"Could not get Cryptometer data for {symbol}: {e}")

        return None

    def _trim_symbol_alerts(self, symbol: str):
        """Keep only the best alerts for a symbol"""
        alerts = self.symbol_alerts_db[symbol]

        if len(alerts) > self.config['max_alerts_per_symbol']:
            # Sort by confidence score and keep the best ones
            alerts.sort(key=lambda x: x.confidence_score, reverse=True)
            self.symbol_alerts_db[symbol] = alerts[:self.config['max_alerts_per_symbol']]

    async def _store_alert(self, alert: AlertData):
        """Store alert in local database"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT OR IGNORE INTO collected_alerts
                    (alert_id, symbol, alert_type, source_server, timestamp, timeframe,
                     signal_strength, confidence_score, technical_data, riskmetric_data,
                     cryptometer_data, market_conditions, action_recommendation, priority_level, status)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    alert.alert_id, alert.symbol, alert.alert_type, alert.source_server,
                    alert.timestamp.isoformat(), alert.timeframe, alert.signal_strength,
                    alert.confidence_score, json.dumps(alert.technical_data),
                    json.dumps(alert.riskmetric_data), json.dumps(alert.cryptometer_data),
                    json.dumps(alert.market_conditions), alert.action_recommendation,
                    alert.priority_level, alert.status
                ))

        except Exception as e:
            logger.error(f"Error storing alert {alert.alert_id}: {e}")

    async def _ensure_symbol_coverage(self):
        """Ensure every symbol has at least one alert prepared"""
        try:
            # Get list of symbols from My Symbols database
            symbols = await self._get_tracked_symbols()

            for symbol in symbols:
                # Check if symbol has sufficient alerts
                if not self._has_sufficient_alerts(symbol):
                    await self._generate_alert_report(symbol)

        except Exception as e:
            logger.error(f"Error ensuring symbol coverage: {e}")

    async def _get_tracked_symbols(self) -> List[str]:
        """Get list of tracked symbols from My Symbols database"""
        try:
            # Try to get from My Symbols database
            my_symbols_db = Path("data/my_symbols_v2.db")

            if my_symbols_db.exists():
                with sqlite3.connect(my_symbols_db) as conn:
                    cursor = conn.execute("SELECT DISTINCT symbol FROM my_symbols WHERE status = 'active'")
                    return [row[0] for row in cursor.fetchall()]

            # Fallback to default symbols
            return [
                'BTC', 'ETH', 'BNB', 'SOL', 'ADA', 'AVAX', 'DOT', 'MATIC', 'LINK', 'UNI',
                'LTC', 'XRP', 'ATOM', 'NEAR', 'ALGO', 'VET', 'FTM', 'SAND', 'MANA', 'CRV',
                'SUSHI', 'AAVE', 'SNX', 'COMP', 'MKR'
            ]

        except Exception as e:
            logger.warning(f"Could not get tracked symbols: {e}")
            return ['BTC', 'ETH', 'BNB']  # Minimal fallback

    def _has_sufficient_alerts(self, symbol: str) -> bool:
        """Check if symbol has sufficient recent alerts"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT COUNT(*) FROM alert_reports
                    WHERE symbol = ? AND is_active = 1
                    AND created_at > datetime('now', '-24 hours')
                ''', (symbol,))

                count = cursor.fetchone()[0]
                return count > 0

        except Exception as e:
            logger.error(f"Error checking alerts for {symbol}: {e}")
            return False

    async def _generate_alert_report(self, symbol: str):
        """Generate a professional alert report for a symbol"""
        try:
            logger.info(f"ðŸ“ Generating alert report for {symbol}")

            # Get all available data for the symbol
            riskmetric_data = await self._get_riskmetric_data(symbol)
            cryptometer_data = await self._get_cryptometer_data(symbol)
            recent_alerts = self._get_recent_alerts(symbol)

            # Generate professional report
            report = await self._create_professional_report(
                symbol, riskmetric_data, cryptometer_data, recent_alerts
            )

            # Store report
            await self._store_alert_report(report)

            self.stats['reports_generated'] += 1
            logger.info(f"âœ… Generated report for {symbol}")

        except Exception as e:
            logger.error(f"Error generating report for {symbol}: {e}")

    def _get_recent_alerts(self, symbol: str) -> List[AlertData]:
        """Get recent alerts for a symbol"""
        return [alert for alert in self.symbol_alerts_db[symbol]
                if (datetime.now() - alert.timestamp).hours < self.config['alert_expiry_hours']]

    async def _create_professional_report(self, symbol: str, riskmetric_data: Optional[Dict],
                                        cryptometer_data: Optional[Dict],
                                        recent_alerts: List[AlertData]) -> AlertReport:
        """Create a professional alert report with MDC documentation"""

        # Analyze data and create comprehensive report
        confidence_rating = self._calculate_overall_confidence(recent_alerts, riskmetric_data, cryptometer_data)

        # Generate professional content
        alert_summary = self._generate_alert_summary(symbol, recent_alerts, confidence_rating)
        technical_analysis = self._generate_technical_analysis(cryptometer_data, recent_alerts)
        risk_assessment = self._generate_risk_assessment(riskmetric_data, symbol)
        market_context = self._generate_market_context(symbol, recent_alerts)
        action_plan = self._generate_action_plan(symbol, confidence_rating, recent_alerts)
        mdc_content = self._generate_mdc_content(symbol, alert_summary, technical_analysis,
                                               risk_assessment, action_plan)

        # Determine data sources
        data_sources = ['Alert Servers']
        if riskmetric_data:
            data_sources.append('RiskMetric Agent')
        if cryptometer_data:
            data_sources.append('Cryptometer System')

        return AlertReport(
            symbol=symbol,
            alert_summary=alert_summary,
            technical_analysis=technical_analysis,
            risk_assessment=risk_assessment,
            market_context=market_context,
            action_plan=action_plan,
            confidence_rating=confidence_rating,
            mdc_content=mdc_content,
            created_at=datetime.now(),
            data_sources=data_sources
        )

    def _calculate_overall_confidence(self, alerts: List[AlertData],
                                    riskmetric_data: Optional[Dict],
                                    cryptometer_data: Optional[Dict]) -> str:
        """Calculate overall confidence rating"""
        scores = []

        # Add alert confidence scores
        for alert in alerts:
            scores.append(alert.confidence_score)

        # Add RiskMetric confidence if available
        if riskmetric_data and 'confidence' in riskmetric_data:
            scores.append(riskmetric_data['confidence'])

        # Add Cryptometer confidence if available
        if cryptometer_data and 'enhanced_prediction' in cryptometer_data:
            enhanced = cryptometer_data['enhanced_prediction']
            avg_confidence = 0
            count = 0
            for timeframe in ['short_term', 'medium_term', 'long_term']:
                if timeframe in enhanced and 'score' in enhanced[timeframe]:
                    avg_confidence += enhanced[timeframe]['score'] / 100
                    count += 1
            if count > 0:
                scores.append(avg_confidence / count)

        if not scores:
            return "Medium"

        avg_score = sum(scores) / len(scores)

        if avg_score >= 0.9:
            return "Extraordinary"
        elif avg_score >= 0.8:
            return "High"
        elif avg_score >= 0.6:
            return "Medium"
        else:
            return "Low"

    def _generate_alert_summary(self, symbol: str, alerts: List[AlertData], confidence: str) -> str:
        """Generate professional alert summary"""
        if not alerts:
            return f"**{symbol} Market Analysis Summary**\n\nBased on comprehensive technical analysis and market data, {symbol} presents a {confidence.lower()} confidence opportunity for strategic positioning. Multiple indicator confluence suggests optimal entry conditions may be developing."

        alert_types = list(set(alert.alert_type for alert in alerts))
        avg_strength = sum(alert.signal_strength for alert in alerts) / len(alerts)

        return f"""**{symbol} Alert Summary - {confidence} Confidence**

ðŸŽ¯ **Signal Confluence Detected**: {len(alerts)} high-quality signals from {len(set(alert.source_server for alert in alerts))} specialized alert systems.

ðŸ“Š **Alert Types**: {', '.join(alert_types)}
ðŸ’ª **Average Signal Strength**: {avg_strength:.2f}
â° **Analysis Timeframe**: Multi-timeframe convergence analysis

**Executive Summary**: {symbol} demonstrates strong technical momentum with {confidence.lower()} confidence rating based on proprietary ZmartBot algorithms. Multiple specialized detection systems confirm optimal market conditions for strategic positioning."""

    def _generate_technical_analysis(self, cryptometer_data: Optional[Dict], alerts: List[AlertData]) -> str:
        """Generate detailed technical analysis"""
        analysis = f"**Technical Analysis Report**\n\n"

        if cryptometer_data and 'enhanced_prediction' in cryptometer_data:
            enhanced = cryptometer_data['enhanced_prediction']

            analysis += "ðŸ” **Multi-Timeframe Cryptometer Analysis**:\n"
            for timeframe in ['short_term', 'medium_term', 'long_term']:
                if timeframe in enhanced:
                    score = enhanced[timeframe].get('score', 0)
                    analysis += f"- **{timeframe.replace('_', ' ').title()}**: {score:.1f}/100 prediction score\n"

        if alerts:
            analysis += f"\nðŸ“¡ **Alert System Analysis**:\n"
            for alert in alerts[:3]:  # Show top 3 alerts
                analysis += f"- **{alert.source_server}**: {alert.alert_type} signal ({alert.confidence_score:.1%} confidence)\n"

        analysis += "\nðŸ’¡ **Technical Insight**: Advanced pattern recognition algorithms detect favorable risk/reward ratio with confluence of multiple technical indicators."

        return analysis

    def _generate_risk_assessment(self, riskmetric_data: Optional[Dict], symbol: str) -> str:
        """Generate risk assessment"""
        if riskmetric_data and 'risk_level' in riskmetric_data:
            risk_level = riskmetric_data['risk_level']
            return f"""**Risk Assessment - {symbol}**

ðŸ›¡ï¸ **RiskMetric Analysis**: {risk_level} risk classification
ðŸ“ˆ **Market Volatility**: Managed risk exposure with defined parameters
âš–ï¸ **Risk/Reward Ratio**: Favorable based on proprietary RiskMetric algorithms

**Risk Management**: Position sizing recommendations align with current market volatility and portfolio risk parameters."""

        return f"""**Risk Assessment - {symbol}**

ðŸ›¡ï¸ **Risk Level**: Moderate (based on market analysis)
ðŸ“Š **Volatility Analysis**: Standard crypto market risk parameters apply
âš–ï¸ **Position Sizing**: Recommended 1-3% portfolio allocation

**Risk Considerations**: Standard cryptocurrency volatility with technical confluence supporting entry timing."""

    def _generate_market_context(self, symbol: str, alerts: List[AlertData]) -> str:
        """Generate market context analysis"""
        return f"""**Market Context Analysis**

ðŸŒ **Current Market Regime**: Technical analysis indicates favorable conditions for {symbol}
ðŸ“Š **Volume Profile**: {len(alerts)} concurrent signals suggest institutional interest
ðŸ”„ **Market Cycle**: Positioned for potential momentum continuation
â° **Timing**: Multi-timeframe alignment creates optimal entry window

**Market Intelligence**: ZmartBot's proprietary alert fusion indicates high-probability setup development."""

    def _generate_action_plan(self, symbol: str, confidence: str, alerts: List[AlertData]) -> str:
        """Generate actionable trading plan"""
        action_level = "MONITOR" if confidence == "Low" else "CONSIDER" if confidence == "Medium" else "EXECUTE"

        return f"""**Recommended Action Plan - {symbol}**

ðŸŽ¯ **Action Level**: {action_level}
ðŸ“Š **Entry Strategy**: {'Gradual accumulation' if confidence in ['Medium', 'High'] else 'Wait for confirmation'}
ðŸ›¡ï¸ **Risk Management**: Stop-loss and position sizing per portfolio guidelines
ðŸ“ˆ **Profit Targets**: Based on technical resistance levels and momentum indicators

**Execution Notes**:
- Monitor for additional confirmation signals
- Scale position based on market response
- Maintain disciplined risk management protocols

**Next Review**: 4-6 hours or upon significant market development"""

    def _generate_mdc_content(self, symbol: str, summary: str, technical: str,
                            risk: str, action: str) -> str:
        """Generate MDC (Markdown Documentation) content"""
        return f"""# {symbol} Alert Report - ZmartBot Professional Analysis

> Type: alert-report | Version: 1.0.0 | Owner: zmartbot | Generated: {datetime.now().isoformat()}

## Executive Summary

{summary}

## Technical Analysis

{technical}

## Risk Assessment

{risk}

## Recommended Actions

{action}

## Data Sources

- ZmartBot Alert Collection Agent
- Multi-server alert fusion (WhaleAlerts, MessiAlerts, LiveAlerts)
- RiskMetric Autonomous Agent
- Cryptometer Enhanced Prediction System
- 21-Indicator Technical Analysis Suite

## Disclaimer

This analysis is generated by ZmartBot's AI-powered alert system for informational purposes. Past performance does not guarantee future results. Always conduct your own research and consider your risk tolerance before making trading decisions.

---
*Generated by ZmartBot Alert Collection Agent | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    async def _store_alert_report(self, report: AlertReport):
        """Store alert report in database"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Deactivate old reports for this symbol
                conn.execute('''
                    UPDATE alert_reports SET is_active = 0
                    WHERE symbol = ? AND is_active = 1
                ''', (report.symbol,))

                # Insert new report
                conn.execute('''
                    INSERT INTO alert_reports
                    (symbol, alert_summary, technical_analysis, risk_assessment,
                     market_context, action_plan, confidence_rating, mdc_content, data_sources)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    report.symbol, report.alert_summary, report.technical_analysis,
                    report.risk_assessment, report.market_context, report.action_plan,
                    report.confidence_rating, report.mdc_content, json.dumps(report.data_sources)
                ))

                # Update symbol coverage
                conn.execute('''
                    INSERT OR REPLACE INTO symbol_coverage
                    (symbol, last_alert_time, alert_count, best_alert_confidence, status)
                    VALUES (?, ?, 1, ?, 'covered')
                ''', (report.symbol, datetime.now().isoformat(), 0.8))  # Default confidence

        except Exception as e:
            logger.error(f"Error storing alert report for {report.symbol}: {e}")

    async def _generate_manus_report(self, alert: AlertData):
        """Generate extraordinary report using Manus for high-scoring alerts"""
        if not self.config['enable_manus_integration']:
            return

        try:
            logger.info(f"ðŸŒŸ Generating Manus extraordinary report for {alert.symbol}")

            # Prepare comprehensive prompt for Manus
            prompt = self._create_manus_prompt(alert)

            # Call Manus (placeholder - would need actual Manus integration)
            manus_report = await self._call_manus(prompt)

            if manus_report:
                # Store extraordinary report
                await self._store_manus_report(alert.symbol, manus_report)
                self.stats['manus_reports'] += 1
                logger.info(f"âœ¨ Manus extraordinary report generated for {alert.symbol}")

        except Exception as e:
            logger.error(f"Error generating Manus report for {alert.symbol}: {e}")

    def _create_manus_prompt(self, alert: AlertData) -> str:
        """Create comprehensive prompt for Manus analysis"""
        return f"""Generate an extraordinary trading intelligence report for {alert.symbol}.

**Alert Context**:
- Signal Strength: {alert.signal_strength:.2f}
- Confidence: {alert.confidence_score:.1%}
- Source: {alert.source_server}
- Type: {alert.alert_type}
- Timeframe: {alert.timeframe}

**Technical Data**: {json.dumps(alert.technical_data, indent=2)}

**RiskMetric Analysis**: {json.dumps(alert.riskmetric_data, indent=2) if alert.riskmetric_data else 'Not available'}

**Cryptometer Data**: {json.dumps(alert.cryptometer_data, indent=2) if alert.cryptometer_data else 'Not available'}

**Market Conditions**: {json.dumps(alert.market_conditions, indent=2)}

Please provide:
1. Deep market analysis with institutional perspective
2. Advanced risk assessment with portfolio implications
3. Strategic positioning recommendations
4. Market timing insights
5. Professional-grade trading intelligence

Focus on exceptional insights that justify the extraordinary confidence rating."""

    async def _call_manus(self, prompt: str) -> Optional[str]:
        """Call Manus for extraordinary analysis (placeholder)"""
        # This would integrate with the actual Manus system
        # For now, return a simulated response
        return f"Extraordinary market intelligence report generated at {datetime.now()}"

    async def _store_manus_report(self, symbol: str, report: str):
        """Store Manus extraordinary report"""
        # Implementation would store the Manus report in appropriate location
        logger.info(f"Stored Manus report for {symbol}")

    async def _sync_to_supabase(self):
        """Sync alert data to Supabase"""
        if not self.config['enable_supabase_sync']:
            return

        try:
            # Placeholder for Supabase integration
            # Would sync processed alerts and reports to Supabase tables
            logger.info("ðŸ“¤ Syncing alert data to Supabase...")
            self.stats['last_supabase_sync'] = datetime.now()

        except Exception as e:
            logger.error(f"Error syncing to Supabase: {e}")

    def _update_stats(self):
        """Update agent statistics"""
        try:
            self.stats['symbols_covered'] = len(self.symbol_alerts_db)

            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO agent_stats
                    (alerts_collected, alerts_processed, reports_generated,
                     manus_reports, symbols_covered)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    self.stats['alerts_collected'],
                    self.stats['alerts_processed'],
                    self.stats['reports_generated'],
                    self.stats['manus_reports'],
                    self.stats['symbols_covered']
                ))

        except Exception as e:
            logger.error(f"Error updating stats: {e}")

    async def get_alert_for_symbol(self, symbol: str) -> Optional[AlertReport]:
        """Get the latest alert report for a symbol (called by ZmartBot Master Agent)"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT alert_summary, technical_analysis, risk_assessment,
                           market_context, action_plan, confidence_rating, mdc_content,
                           data_sources, created_at
                    FROM alert_reports
                    WHERE symbol = ? AND is_active = 1
                    ORDER BY created_at DESC LIMIT 1
                ''', (symbol.upper(),))

                row = cursor.fetchone()
                if row:
                    return AlertReport(
                        symbol=symbol.upper(),
                        alert_summary=row[0],
                        technical_analysis=row[1],
                        risk_assessment=row[2],
                        market_context=row[3],
                        action_plan=row[4],
                        confidence_rating=row[5],
                        mdc_content=row[6],
                        data_sources=json.loads(row[7]),
                        created_at=datetime.fromisoformat(row[8])
                    )

                return None

        except Exception as e:
            logger.error(f"Error getting alert for {symbol}: {e}")
            return None

    def get_agent_status(self) -> Dict[str, Any]:
        """Get current agent status and statistics"""
        return {
            'agent': 'alert_collection_agent',
            'status': 'active' if self.config['autonomous_mode'] else 'standby',
            'stats': self.stats,
            'config': self.config,
            'symbols_covered': len(self.symbol_alerts_db),
            'alerts_in_queue': len(self.alert_queue),
            'database_path': str(self.db_path),
            'last_updated': datetime.now().isoformat()
        }

# Global instance
_alert_agent = None

def get_alert_collection_agent() -> AlertCollectionAgent:
    """Get or create the alert collection agent instance"""
    global _alert_agent
    if _alert_agent is None:
        _alert_agent = AlertCollectionAgent()
    return _alert_agent

async def main():
    """Main function for running the Alert Collection Agent"""
    try:
        agent = AlertCollectionAgent()

        if len(sys.argv) > 1:
            command = sys.argv[1].lower()

            if command == 'start':
                await agent.start_autonomous_collection()
            elif command == 'status':
                status = agent.get_agent_status()
                print(json.dumps(status, indent=2))
            elif command == 'test':
                # Test collection cycle
                await agent._collect_all_alerts()
                await agent._process_alerts_with_data()
                await agent._ensure_symbol_coverage()
                print("âœ… Test cycle completed")
            else:
                print("Usage: python alert_collection_agent.py [start|status|test]")
        else:
            await agent.start_autonomous_collection()

    except KeyboardInterrupt:
        logger.info("ðŸ‘‹ Alert Collection Agent stopped by user")
    except Exception as e:
        logger.error(f"ðŸ’¥ Fatal error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())