#!/usr/bin/env python3
"""
üöÄ PREMIUM AI ORCHESTRATOR - ENTERPRISE GRADE
Advanced AI coordination service with intelligent routing, memory context, 
and enterprise-level conversation management for ZmartBot Premium
"""

import os
import sys
import json
import logging
import asyncio
import argparse
import sqlite3
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from flask import Flask, request, jsonify
from flask_cors import CORS
import hashlib
import aiohttp
# Setup logging first
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import dependencies with fallbacks
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    logger.warning("tiktoken not available, using simple token counting")

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    logger.warning("sentence-transformers not available, using basic memory search")

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("openai not available")

# Setup enterprise logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('premium_ai.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class PremiumAIRequest:
    """Premium AI request with advanced context"""
    user_id: str
    session_id: str
    message: str
    context_type: str  # 'crypto', 'trading', 'general', 'analysis'
    preferred_model: Optional[str] = None
    include_memory: bool = True
    include_market_data: bool = True
    response_format: str = 'conversational'  # 'conversational', 'analytical', 'brief'
    confidence_threshold: float = 0.85

@dataclass
class PremiumAIResponse:
    """Premium AI response with enhanced metadata"""
    response_id: str
    content: str
    model_used: str
    confidence_score: float
    response_time_ms: int
    memory_context_used: bool
    market_data_included: bool
    follow_up_suggestions: List[str]
    sources: List[str]
    metadata: Dict[str, Any]

@dataclass
class MemoryVector:
    """Vector embedding for semantic memory search"""
    memory_id: str
    embedding: List[float]
    content: str
    timestamp: str
    importance_score: float
    context_tags: List[str]

class PremiumAIOrchestrator:
    """
    üåü ENTERPRISE-GRADE AI ORCHESTRATOR
    
    Features:
    - Intelligent AI routing (Claude 3.5 Sonnet, GPT-5 Pro, Hybrid)
    - Vector-based semantic memory search
    - Real-time market data integration
    - Advanced conversation context management
    - Professional response optimization
    - Enterprise-level monitoring and analytics
    """
    
    def __init__(self, project_root: str = None, port: int = 8009):
        self.project_root = Path(project_root) if project_root else Path("../.")
        self.port = port
        self.db_path = self.project_root / "zmart-api" / "premium_ai_database.db"
        
        # Initialize vector embedding model if available
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.info("Loading sentence transformer model...")
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        else:
            self.embedding_model = None
            logger.info("Running without sentence transformers - basic memory search only")
        
        # Initialize tokenizer for context management if available
        if TIKTOKEN_AVAILABLE:
            self.tokenizer = tiktoken.get_encoding("cl100k_base")
        else:
            self.tokenizer = None
            logger.info("Running without tiktoken - using simple token counting")
        
        # Initialize database
        self.init_database()
        
        # Initialize Flask app
        self.app = Flask(__name__)
        CORS(self.app)
        self.setup_routes()
        
        logger.info(f"üöÄ Premium AI Orchestrator initialized - Port: {self.port}")
    
    def init_database(self):
        """Initialize premium AI database with vector storage"""
        try:
            self.db_path.parent.mkdir(parents=True, exist_ok=True)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Premium conversation memories with vector embeddings
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS premium_memories (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    memory_id TEXT UNIQUE NOT NULL,
                    user_id TEXT NOT NULL,
                    session_id TEXT NOT NULL,
                    content TEXT NOT NULL,
                    content_embedding BLOB,
                    ai_model TEXT NOT NULL,
                    context_type TEXT NOT NULL,
                    importance_score REAL DEFAULT 0.5,
                    confidence_score REAL DEFAULT 0.0,
                    context_tags TEXT,
                    market_data TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Premium user profiles with advanced preferences
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS premium_user_profiles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT UNIQUE NOT NULL,
                    trading_experience TEXT DEFAULT 'beginner',
                    preferred_ai_model TEXT DEFAULT 'auto',
                    risk_tolerance TEXT DEFAULT 'moderate',
                    favorite_cryptocurrencies TEXT,
                    communication_style TEXT DEFAULT 'professional',
                    timezone TEXT DEFAULT 'UTC',
                    language TEXT DEFAULT 'en',
                    premium_features TEXT,
                    total_interactions INTEGER DEFAULT 0,
                    avg_session_length INTEGER DEFAULT 0,
                    last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # AI performance analytics
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS ai_performance_analytics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    request_id TEXT UNIQUE NOT NULL,
                    user_id TEXT NOT NULL,
                    ai_model TEXT NOT NULL,
                    response_time_ms INTEGER,
                    confidence_score REAL,
                    user_satisfaction REAL,
                    context_relevance REAL,
                    memory_hits INTEGER DEFAULT 0,
                    market_data_used BOOLEAN DEFAULT FALSE,
                    tokens_used INTEGER,
                    cost_estimate REAL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Real-time conversation context
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS conversation_context (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    context_summary TEXT NOT NULL,
                    active_topics TEXT,
                    sentiment_score REAL DEFAULT 0.0,
                    complexity_level TEXT DEFAULT 'medium',
                    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Create premium indexes for performance
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_premium_user_timestamp ON premium_memories(user_id, timestamp DESC)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_premium_importance ON premium_memories(importance_score DESC)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_premium_context ON premium_memories(context_type, timestamp DESC)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_ai_performance ON ai_performance_analytics(ai_model, timestamp DESC)")
            
            conn.commit()
            conn.close()
            logger.info("‚úÖ Premium AI database initialized with enterprise features")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize premium database: {e}")
            raise
    
    def setup_routes(self):
        """Setup premium API routes with enterprise features"""
        
        @self.app.route('/health', methods=['GET'])
        def health():
            """Premium health check with system metrics"""
            try:
                # Check database connection
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM premium_memories")
                memory_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM premium_user_profiles")
                user_count = cursor.fetchone()[0]
                
                # Check AI model availability
                model_status = {
                    "embedding_model": "‚úÖ loaded",
                    "tokenizer": "‚úÖ loaded",
                    "vector_search": "‚úÖ ready"
                }
                
                conn.close()
                
                return jsonify({
                    "status": "üöÄ premium_healthy",
                    "timestamp": datetime.now().isoformat(),
                    "service": "premium-ai-orchestrator",
                    "version": "2.0.0-enterprise",
                    "metrics": {
                        "total_memories": memory_count,
                        "active_users": user_count,
                        "models": model_status
                    }
                })
                
            except Exception as e:
                return jsonify({
                    "status": "‚ö†Ô∏è degraded",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }), 503
        
        @self.app.route('/ai/premium-chat', methods=['POST'])
        def premium_chat():
            """üåü PREMIUM AI CHAT - Enterprise Grade"""
            start_time = datetime.now()
            
            try:
                data = request.get_json()
                if not data:
                    return jsonify({"error": "No data provided"}), 400
                
                # Create premium request
                ai_request = PremiumAIRequest(
                    user_id=data.get('user_id'),
                    session_id=data.get('session_id'),
                    message=data.get('message'),
                    context_type=data.get('context_type', 'general'),
                    preferred_model=data.get('preferred_model'),
                    include_memory=data.get('include_memory', True),
                    include_market_data=data.get('include_market_data', True),
                    response_format=data.get('response_format', 'conversational'),
                    confidence_threshold=data.get('confidence_threshold', 0.85)
                )
                
                # Generate premium response
                response = self.generate_premium_response(ai_request)
                
                # Calculate response time
                response_time = (datetime.now() - start_time).total_seconds() * 1000
                response.response_time_ms = int(response_time)
                
                # Store analytics
                self.store_analytics(ai_request, response, response_time)
                
                logger.info(f"üåü Premium response generated for user {ai_request.user_id} in {response_time:.0f}ms")
                
                return jsonify(asdict(response))
                
            except Exception as e:
                logger.error(f"‚ùå Premium chat failed: {e}")
                return jsonify({"error": str(e)}), 500
        
        @self.app.route('/memory/smart-search', methods=['POST'])
        def smart_memory_search():
            """üß† INTELLIGENT MEMORY SEARCH with Vector Similarity"""
            try:
                data = request.get_json()
                query = data.get('query')
                user_id = data.get('user_id')
                limit = data.get('limit', 5)
                similarity_threshold = data.get('similarity_threshold', 0.7)
                
                if not query or not user_id:
                    return jsonify({"error": "Query and user_id required"}), 400
                
                # Perform vector similarity search
                results = self.vector_memory_search(user_id, query, limit, similarity_threshold)
                
                return jsonify({
                    "query": query,
                    "results": results,
                    "search_type": "vector_similarity",
                    "threshold": similarity_threshold
                })
                
            except Exception as e:
                logger.error(f"Smart memory search failed: {e}")
                return jsonify({"error": str(e)}), 500
        
        @self.app.route('/analytics/premium-dashboard', methods=['GET'])
        def premium_analytics_dashboard():
            """üìä PREMIUM ANALYTICS DASHBOARD"""
            try:
                user_id = request.args.get('user_id')
                days = int(request.args.get('days', 7))
                
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                # Get comprehensive analytics
                analytics = self.get_premium_analytics(cursor, user_id, days)
                
                conn.close()
                
                return jsonify(analytics)
                
            except Exception as e:
                logger.error(f"Premium analytics failed: {e}")
                return jsonify({"error": str(e)}), 500
        
        @self.app.route('/profile/premium-user/<user_id>', methods=['GET', 'POST'])
        def premium_user_profile(user_id):
            """üë§ PREMIUM USER PROFILE MANAGEMENT"""
            try:
                if request.method == 'POST':
                    # Update profile
                    data = request.get_json()
                    self.update_premium_profile(user_id, data)
                    return jsonify({"success": True, "message": "Premium profile updated"})
                else:
                    # Get profile
                    profile = self.get_premium_profile(user_id)
                    return jsonify(profile)
                
            except Exception as e:
                logger.error(f"Premium profile operation failed: {e}")
                return jsonify({"error": str(e)}), 500
    
    def generate_premium_response(self, request: PremiumAIRequest) -> PremiumAIResponse:
        """üåü Generate premium AI response with intelligent routing"""
        
        # 1. Analyze request and determine optimal AI model
        optimal_model = self.determine_optimal_ai_model(request)
        
        # 2. Retrieve relevant memory context
        memory_context = []
        if request.include_memory:
            memory_context = self.vector_memory_search(
                request.user_id, 
                request.message, 
                limit=5, 
                threshold=0.6
            )
        
        # 3. Get market data if needed
        market_data = {}
        if request.include_market_data and request.context_type in ['crypto', 'trading']:
            market_data = self.get_real_time_market_data(request.message)
        
        # 4. Build enhanced context
        enhanced_context = self.build_enhanced_context(request, memory_context, market_data)
        
        # 5. Generate response with selected AI model
        if optimal_model == 'claude':
            response_content = self.call_claude_premium(enhanced_context, request)
        elif optimal_model == 'openai':
            response_content = self.call_openai_premium(enhanced_context, request)
        else:
            response_content = self.call_hybrid_ai(enhanced_context, request)
        
        # 6. Generate follow-up suggestions
        follow_ups = self.generate_follow_up_suggestions(request, response_content)
        
        # 7. Store memory with vector embedding
        if response_content:
            self.store_premium_memory(request, response_content, optimal_model)
        
        # 8. Calculate confidence score
        confidence = self.calculate_response_confidence(response_content, memory_context, market_data)
        
        return PremiumAIResponse(
            response_id=hashlib.sha256(f"{request.session_id}_{datetime.now()}".encode()).hexdigest()[:12],
            content=response_content,
            model_used=optimal_model,
            confidence_score=confidence,
            response_time_ms=0,  # Will be set by caller
            memory_context_used=len(memory_context) > 0,
            market_data_included=len(market_data) > 0,
            follow_up_suggestions=follow_ups,
            sources=[optimal_model, "premium_memory", "real_time_data"],
            metadata={
                "context_type": request.context_type,
                "memory_hits": len(memory_context),
                "market_symbols": list(market_data.keys()) if market_data else [],
                "response_format": request.response_format
            }
        )
    
    def determine_optimal_ai_model(self, request: PremiumAIRequest) -> str:
        """üß† Intelligent AI model selection based on context"""
        
        # User preference override
        if request.preferred_model and request.preferred_model != 'auto':
            return request.preferred_model
        
        # Context-based routing
        if request.context_type == 'crypto':
            if 'price' in request.message.lower() or 'chart' in request.message.lower():
                return 'openai'  # Better for real-time data analysis
            else:
                return 'claude'  # Better for conversational crypto advice
        
        elif request.context_type == 'trading':
            return 'hybrid'  # Best for complex trading analysis
        
        elif request.context_type == 'analysis':
            return 'openai'  # Excellent for analytical tasks
        
        else:
            return 'claude'  # Best for general conversation
    
    def vector_memory_search(self, user_id: str, query: str, limit: int = 5, threshold: float = 0.6) -> List[Dict]:
        """üîç Vector-based semantic memory search"""
        try:
            # If no embedding model available, do basic text search
            if not self.embedding_model:
                return self.basic_memory_search(user_id, query, limit)
            
            # Generate query embedding
            query_embedding = self.embedding_model.encode([query])[0]
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Get all memories for user
            cursor.execute("""
                SELECT memory_id, content, content_embedding, context_type, importance_score, 
                       context_tags, timestamp
                FROM premium_memories 
                WHERE user_id = ? AND content_embedding IS NOT NULL
                ORDER BY timestamp DESC
                LIMIT 50
            """, (user_id,))
            
            memories = cursor.fetchall()
            conn.close()
            
            # Calculate similarities
            similar_memories = []
            for memory in memories:
                if memory[2]:  # Has embedding
                    memory_embedding = np.frombuffer(memory[2], dtype=np.float32)
                    similarity = np.dot(query_embedding, memory_embedding) / (
                        np.linalg.norm(query_embedding) * np.linalg.norm(memory_embedding)
                    )
                    
                    if similarity >= threshold:
                        similar_memories.append({
                            "memory_id": memory[0],
                            "content": memory[1],
                            "context_type": memory[3],
                            "importance_score": memory[4],
                            "context_tags": json.loads(memory[5]) if memory[5] else [],
                            "timestamp": memory[6],
                            "similarity_score": float(similarity)
                        })
            
            # Sort by similarity and importance
            similar_memories.sort(key=lambda x: x['similarity_score'] * x['importance_score'], reverse=True)
            
            return similar_memories[:limit]
            
        except Exception as e:
            logger.error(f"Vector memory search failed: {e}")
            return self.basic_memory_search(user_id, query, limit)
    
    def basic_memory_search(self, user_id: str, query: str, limit: int = 5) -> List[Dict]:
        """üîç Basic text-based memory search (fallback)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Simple text search with LIKE operator
            search_terms = query.lower().split()
            search_condition = " OR ".join([f"LOWER(content) LIKE ?" for _ in search_terms])
            search_params = [f"%{term}%" for term in search_terms] + [user_id]
            
            cursor.execute(f"""
                SELECT memory_id, content, context_type, importance_score, 
                       context_tags, timestamp
                FROM premium_memories 
                WHERE ({search_condition}) AND user_id = ?
                ORDER BY importance_score DESC, timestamp DESC
                LIMIT ?
            """, search_params + [limit])
            
            memories = cursor.fetchall()
            conn.close()
            
            # Format results
            results = []
            for memory in memories:
                results.append({
                    "memory_id": memory[0],
                    "content": memory[1],
                    "context_type": memory[2],
                    "importance_score": memory[3],
                    "context_tags": json.loads(memory[4]) if memory[4] else [],
                    "timestamp": memory[5],
                    "similarity_score": 0.8  # Default similarity for text search
                })
            
            return results
            
        except Exception as e:
            logger.error(f"Basic memory search failed: {e}")
            return []
    
    def build_enhanced_context(self, request: PremiumAIRequest, memory_context: List[Dict], market_data: Dict) -> str:
        """üèóÔ∏è Build enhanced context for AI models"""
        
        context_parts = []
        
        # User profile context
        profile = self.get_premium_profile(request.user_id)
        if profile:
            context_parts.append(f"User Profile: {profile['trading_experience']} trader, prefers {profile['communication_style']} style")
        
        # Memory context
        if memory_context:
            context_parts.append("Recent Relevant Conversations:")
            for memory in memory_context[:3]:
                context_parts.append(f"- {memory['content'][:100]}... (similarity: {memory['similarity_score']:.2f})")
        
        # Market data context
        if market_data:
            context_parts.append("Current Market Data:")
            for symbol, data in market_data.items():
                context_parts.append(f"- {symbol}: ${data.get('price', 'N/A')} ({data.get('change', 'N/A')}%)")
        
        # Current request
        context_parts.append(f"Current Query ({request.context_type}): {request.message}")
        
        return "\n".join(context_parts)
    
    def call_claude_premium(self, context: str, request: PremiumAIRequest) -> str:
        """ü§ñ Call Claude with premium features"""
        try:
            # This would integrate with your API manager
            import requests
            
            response = requests.post('http://localhost:8007/claude-api')
            api_config = response.json()
            
            # Make Claude API call with enhanced context
            claude_response = requests.post(
                api_config['endpoint'],
                headers={
                    'Content-Type': 'application/json',
                    'x-api-key': api_config['api_key'],
                    'anthropic-version': api_config['version']
                },
                json={
                    'model': api_config['model'],
                    'max_tokens': 1000,
                    'messages': [
                        {
                            'role': 'system',
                            'content': f"""You are Zmarty, an advanced AI trading assistant with premium capabilities.
                            
Context Information:
{context}

Please provide a comprehensive, professional response that demonstrates deep understanding and expertise."""
                        },
                        {
                            'role': 'user', 
                            'content': request.message
                        }
                    ]
                }
            )
            
            if claude_response.status_code == 200:
                result = claude_response.json()
                return result['content'][0]['text']
            else:
                return "I apologize, but I'm experiencing technical difficulties. Please try again."
                
        except Exception as e:
            logger.error(f"Claude premium call failed: {e}")
            return "I'm having trouble connecting to my advanced systems. Let me provide a basic response while I resolve this."
    
    def call_openai_premium(self, context: str, request: PremiumAIRequest) -> str:
        """üöÄ Call OpenAI Premium with advanced features"""
        try:
            # Placeholder for OpenAI integration
            return f"üöÄ **Premium OpenAI Analysis**\n\nBased on the context and your query: '{request.message}'\n\nI'm analyzing real-time data and providing advanced insights. This would integrate with GPT-5 Pro through your API manager."
            
        except Exception as e:
            logger.error(f"OpenAI premium call failed: {e}")
            return "Premium OpenAI service temporarily unavailable."
    
    def call_hybrid_ai(self, context: str, request: PremiumAIRequest) -> str:
        """üåü Call hybrid AI system"""
        try:
            # Combine insights from multiple models
            claude_response = self.call_claude_premium(context, request)
            
            return f"üåü **Hybrid AI Response**\n\n{claude_response}\n\n*This response combines insights from multiple AI models for maximum accuracy and depth.*"
            
        except Exception as e:
            logger.error(f"Hybrid AI call failed: {e}")
            return "Hybrid AI system temporarily unavailable."
    
    def store_premium_memory(self, request: PremiumAIRequest, response: str, model: str):
        """üíæ Store memory with vector embedding"""
        try:
            # Generate embedding
            content_embedding = self.embedding_model.encode([response])[0]
            embedding_blob = content_embedding.astype(np.float32).tobytes()
            
            # Extract context tags
            context_tags = self.extract_context_tags(request.message, response)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            memory_id = hashlib.sha256(f"{request.user_id}_{response}_{datetime.now()}".encode()).hexdigest()[:16]
            
            cursor.execute("""
                INSERT INTO premium_memories 
                (memory_id, user_id, session_id, content, content_embedding, ai_model, 
                 context_type, importance_score, context_tags)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                memory_id, request.user_id, request.session_id, response,
                embedding_blob, model, request.context_type, 0.7,
                json.dumps(context_tags)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Premium memory storage failed: {e}")
    
    def extract_context_tags(self, message: str, response: str) -> List[str]:
        """üè∑Ô∏è Extract context tags from conversation"""
        tags = []
        
        # Crypto-related tags
        crypto_keywords = ['bitcoin', 'ethereum', 'btc', 'eth', 'crypto', 'blockchain', 'defi']
        for keyword in crypto_keywords:
            if keyword in message.lower() or keyword in response.lower():
                tags.append(keyword)
        
        # Trading tags
        trading_keywords = ['buy', 'sell', 'trade', 'price', 'market', 'analysis', 'chart']
        for keyword in trading_keywords:
            if keyword in message.lower() or keyword in response.lower():
                tags.append(keyword)
        
        return list(set(tags))
    
    def get_real_time_market_data(self, message: str) -> Dict:
        """üìà Get real-time market data based on message content"""
        # Extract crypto symbols from message
        symbols = []
        crypto_symbols = ['BTC', 'ETH', 'SOL', 'AVAX', 'ADA', 'DOT']
        
        for symbol in crypto_symbols:
            if symbol.lower() in message.lower():
                symbols.append(symbol)
        
        # Mock market data (integrate with your real APIs)
        market_data = {}
        for symbol in symbols:
            market_data[symbol] = {
                "price": 50000 + hash(symbol) % 10000,
                "change": (hash(symbol) % 20) - 10,
                "volume": 1000000000
            }
        
        return market_data
    
    def generate_follow_up_suggestions(self, request: PremiumAIRequest, response: str) -> List[str]:
        """üí° Generate intelligent follow-up suggestions"""
        
        if request.context_type == 'crypto':
            return [
                "Would you like me to analyze the charts for this cryptocurrency?",
                "Should I check the latest news affecting this market?",
                "Want to see the risk assessment for this investment?"
            ]
        elif request.context_type == 'trading':
            return [
                "Would you like me to create a trading strategy?",
                "Should I analyze the risk/reward ratio?",
                "Want to see similar trading opportunities?"
            ]
        else:
            return [
                "Would you like more detailed analysis?",
                "Should I explain any specific concepts?",
                "Need help with the next steps?"
            ]
    
    def calculate_response_confidence(self, response: str, memory_context: List[Dict], market_data: Dict) -> float:
        """üìä Calculate response confidence score"""
        confidence = 0.5  # Base confidence
        
        # Boost confidence based on memory context
        if memory_context:
            confidence += min(0.3, len(memory_context) * 0.1)
        
        # Boost confidence if market data is available
        if market_data:
            confidence += 0.15
        
        # Boost confidence based on response length and detail
        if len(response) > 200:
            confidence += 0.1
        
        return min(1.0, confidence)
    
    def get_premium_profile(self, user_id: str) -> Dict:
        """üë§ Get premium user profile"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT trading_experience, preferred_ai_model, risk_tolerance, 
                       favorite_cryptocurrencies, communication_style, total_interactions
                FROM premium_user_profiles 
                WHERE user_id = ?
            """, (user_id,))
            
            row = cursor.fetchone()
            conn.close()
            
            if row:
                return {
                    "trading_experience": row[0],
                    "preferred_ai_model": row[1], 
                    "risk_tolerance": row[2],
                    "favorite_cryptocurrencies": json.loads(row[3]) if row[3] else [],
                    "communication_style": row[4],
                    "total_interactions": row[5]
                }
            else:
                # Create default profile
                self.create_default_profile(user_id)
                return {"trading_experience": "beginner", "communication_style": "professional"}
                
        except Exception as e:
            logger.error(f"Get premium profile failed: {e}")
            return {}
    
    def create_default_profile(self, user_id: str):
        """Create default premium profile for new user"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR IGNORE INTO premium_user_profiles (user_id)
                VALUES (?)
            """, (user_id,))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Create default profile failed: {e}")
    
    def store_analytics(self, request: PremiumAIRequest, response: PremiumAIResponse, response_time: float):
        """üìä Store premium analytics"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO ai_performance_analytics 
                (request_id, user_id, ai_model, response_time_ms, confidence_score, 
                 memory_hits, market_data_used, tokens_used)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                response.response_id, request.user_id, response.model_used,
                int(response_time), response.confidence_score,
                len(response.metadata.get('memory_hits', [])),
                response.market_data_included,
                len(self.tokenizer.encode(response.content))
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Analytics storage failed: {e}")
    
    def get_premium_analytics(self, cursor, user_id: str, days: int) -> Dict:
        """üìà Get premium analytics dashboard data"""
        try:
            since_date = datetime.now() - timedelta(days=days)
            
            # Overall stats
            cursor.execute("""
                SELECT COUNT(*), AVG(confidence_score), AVG(response_time_ms)
                FROM ai_performance_analytics 
                WHERE user_id = ? AND timestamp > ?
            """, (user_id, since_date))
            overall_stats = cursor.fetchone()
            
            # Model performance
            cursor.execute("""
                SELECT ai_model, COUNT(*), AVG(confidence_score), AVG(response_time_ms)
                FROM ai_performance_analytics 
                WHERE user_id = ? AND timestamp > ?
                GROUP BY ai_model
            """, (user_id, since_date))
            model_stats = cursor.fetchall()
            
            return {
                "period_days": days,
                "total_interactions": overall_stats[0] or 0,
                "avg_confidence": round(overall_stats[1] or 0, 2),
                "avg_response_time_ms": round(overall_stats[2] or 0, 0),
                "model_performance": [
                    {
                        "model": row[0],
                        "interactions": row[1],
                        "avg_confidence": round(row[2], 2),
                        "avg_response_time": round(row[3], 0)
                    } for row in model_stats
                ]
            }
            
        except Exception as e:
            logger.error(f"Premium analytics failed: {e}")
            return {"error": str(e)}
    
    def run(self):
        """üöÄ Run the Premium AI Orchestrator"""
        logger.info(f"üåü Starting Premium AI Orchestrator on port {self.port}")
        self.app.run(host='0.0.0.0', port=self.port, debug=False)

def main():
    """Main entry point for Premium AI Orchestrator"""
    parser = argparse.ArgumentParser(description='Premium AI Orchestrator - Enterprise Grade')
    parser.add_argument('--port', type=int, default=8009, help='Port to run on')
    parser.add_argument('--project-root', type=str, help='Project root directory')
    
    args = parser.parse_args()
    
    # Create and run premium service
    service = PremiumAIOrchestrator(
        project_root=args.project_root,
        port=args.port
    )
    
    service.run()

if __name__ == '__main__':
    main()