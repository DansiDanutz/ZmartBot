#!/usr/bin/env python3
"""
KingFisher Master Summary Agent
Composes brilliant professional summaries from all individual symbol analyses
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import httpx
from dataclasses import dataclass
import re

logger = logging.getLogger(__name__)

@dataclass
class SymbolSummary:
    """Data structure for individual symbol summary"""
    symbol: str
    current_price: float
    sentiment: str
    confidence: float
    risk_score: float
    long_ratio_24h: float
    short_ratio_24h: float
    long_ratio_7d: float
    short_ratio_7d: float
    long_ratio_1m: float
    short_ratio_1m: float
    technical_summary: str
    trading_recommendations: str
    analysis_timestamp: str

@dataclass
class MasterSummary:
    """Data structure for the master summary"""
    overall_sentiment: str
    market_confidence: float
    top_performers: List[str]
    risk_alert_symbols: List[str]
    market_trend: str
    sector_analysis: Dict[str, Any]
    trading_opportunities: List[Dict[str, Any]]
    risk_warnings: List[str]
    professional_summary: str
    executive_summary: str
    timestamp: str

class MasterSummaryAgent:
    """Master Summary Agent - Composes brilliant professional summaries from all analyses"""
    
    def __init__(self):
        self.api_key = "patcE6fQFEu7sDjmd.3f556799e233829b3aef09d9387bc3ada86c8eb7eb74616076d90f7f11b70835"
        self.base_id = "appAs9sZH7OmtYaTJ"
        self.table_name = "KingFisher"
        self.base_url = f"https://api.airtable.com/v0/{self.base_id}/{self.table_name}"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    async def get_all_symbol_records(self, hours_back: int = 24) -> List[Dict[str, Any]]:
        """Retrieve all symbol records from Airtable within specified timeframe"""
        try:
            # Get all records from the last N hours
            params = {
                "maxRecords": 100,  # Adjust based on expected volume
                "sort[0][field]": "createdTime",
                "sort[0][direction]": "desc"
            }
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    self.base_url,
                    headers=self.headers,
                    params=params
                )
                
                if response.status_code == 200:
                    result = response.json()
                    records = result.get("records", [])
                    
                    # Filter by timestamp if needed
                    if hours_back:
                        cutoff_time = datetime.now() - timedelta(hours=hours_back)
                        filtered_records = []
                        for record in records:
                            created_time = record.get('createdTime')
                            if created_time:
                                try:
                                    record_time = datetime.fromisoformat(created_time.replace('Z', '+00:00'))
                                    if record_time > cutoff_time:
                                        filtered_records.append(record)
                                except:
                                    continue
                        return filtered_records
                    
                    return records
                else:
                    logger.error(f"‚ùå Error fetching Airtable records: {response.status_code}")
                    return []
                    
        except Exception as e:
            logger.error(f"‚ùå Error getting symbol records: {str(e)}")
            return []
    
    def extract_symbol_summary(self, record: Dict[str, Any]) -> Optional[SymbolSummary]:
        """Extract summary data from a single Airtable record"""
        try:
            fields = record.get('fields', {})
            
            # Extract basic symbol info
            symbol = fields.get('Symbol', '')
            if not symbol:
                return None
            
            # Extract Result field which contains the analysis
            result_field = fields.get('Result', '')
            if isinstance(result_field, str):
                try:
                    result_data = json.loads(result_field)
                except:
                    result_data = {}
            else:
                result_data = result_field
            
            # Extract timeframe data
            timeframe_24h = fields.get('24h48h', 'Long 0%, Short 0%')
            timeframe_7d = fields.get('7days', 'Long 0%, Short 0%')
            timeframe_1m = fields.get('1Month', 'Long 0%, Short 0%')
            
            # Parse long/short ratios
            long_24h, short_24h = self._parse_ratio_field(timeframe_24h)
            long_7d, short_7d = self._parse_ratio_field(timeframe_7d)
            long_1m, short_1m = self._parse_ratio_field(timeframe_1m)
            
            # Extract analysis data
            technical_summary = result_data.get('technical_summary', 'No technical analysis available')
            trading_recommendations = result_data.get('trading_recommendations', 'No recommendations available')
            analysis_timestamp = result_data.get('analysis_timestamp', datetime.now().isoformat())
            
            # Calculate sentiment and confidence from ratios
            sentiment = self._calculate_sentiment(long_24h, short_24h, long_7d, short_7d, long_1m, short_1m)
            confidence = self._calculate_confidence(long_24h, short_24h, long_7d, short_7d, long_1m, short_1m)
            risk_score = self._calculate_risk_score(long_24h, short_24h, long_7d, short_7d, long_1m, short_1m)
            
            # Mock current price (in real implementation, this would come from market data)
            current_price = 0.0  # Would be extracted from market data
            
            return SymbolSummary(
                symbol=symbol,
                current_price=current_price,
                sentiment=sentiment,
                confidence=confidence,
                risk_score=risk_score,
                long_ratio_24h=long_24h,
                short_ratio_24h=short_24h,
                long_ratio_7d=long_7d,
                short_ratio_7d=short_7d,
                long_ratio_1m=long_1m,
                short_ratio_1m=short_1m,
                technical_summary=technical_summary,
                trading_recommendations=trading_recommendations,
                analysis_timestamp=analysis_timestamp
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting symbol summary for {record.get('fields', {}).get('Symbol', 'Unknown')}: {str(e)}")
            return None
    
    def _parse_ratio_field(self, field: str) -> Tuple[float, float]:
        """Parse ratio field like 'Long 80%, Short 20%'"""
        try:
            long_match = re.search(r'Long (\d+)%', field)
            short_match = re.search(r'Short (\d+)%', field)
            
            long_ratio = float(long_match.group(1)) if long_match else 0.0
            short_ratio = float(short_match.group(1)) if short_match else 0.0
            
            return long_ratio, short_ratio
        except:
            return 0.0, 0.0
    
    def _calculate_sentiment(self, long_24h: float, short_24h: float, 
                           long_7d: float, short_7d: float, 
                           long_1m: float, short_1m: float) -> str:
        """Calculate overall sentiment from ratios"""
        # Weight recent data more heavily
        weighted_long = (long_24h * 0.5) + (long_7d * 0.3) + (long_1m * 0.2)
        weighted_short = (short_24h * 0.5) + (short_7d * 0.3) + (short_1m * 0.2)
        
        if weighted_long > weighted_short + 20:
            return "bullish"
        elif weighted_short > weighted_long + 20:
            return "bearish"
        else:
            return "neutral"
    
    def _calculate_confidence(self, long_24h: float, short_24h: float,
                            long_7d: float, short_7d: float,
                            long_1m: float, short_1m: float) -> float:
        """Calculate confidence score based on ratio consistency"""
        # Higher confidence when ratios are consistent across timeframes
        long_consistency = abs(long_24h - long_7d) + abs(long_7d - long_1m)
        short_consistency = abs(short_24h - short_7d) + abs(short_7d - short_1m)
        
        # Lower consistency = higher confidence
        base_confidence = 100 - (long_consistency + short_consistency) / 2
        return max(0.0, min(100.0, base_confidence))
    
    def _calculate_risk_score(self, long_24h: float, short_24h: float,
                            long_7d: float, short_7d: float,
                            long_1m: float, short_1m: float) -> float:
        """Calculate risk score based on volatility and extreme ratios"""
        # Higher risk with extreme ratios and high volatility
        volatility = abs(long_24h - long_7d) + abs(short_24h - short_7d)
        extreme_ratios = max(long_24h, short_24h, long_7d, short_7d, long_1m, short_1m)
        
        risk_score = (volatility * 0.6) + (extreme_ratios * 0.4)
        return min(100.0, risk_score)
    
    def analyze_market_trend(self, summaries: List[SymbolSummary]) -> str:
        """Analyze overall market trend from all symbols"""
        if not summaries:
            return "insufficient_data"
        
        bullish_count = sum(1 for s in summaries if s.sentiment == "bullish")
        bearish_count = sum(1 for s in summaries if s.sentiment == "bearish")
        neutral_count = sum(1 for s in summaries if s.sentiment == "neutral")
        
        total = len(summaries)
        bullish_pct = (bullish_count / total) * 100
        bearish_pct = (bearish_count / total) * 100
        
        if bullish_pct > 60:
            return "bullish"
        elif bearish_pct > 60:
            return "bearish"
        else:
            return "mixed"
    
    def identify_top_performers(self, summaries: List[SymbolSummary], limit: int = 5) -> List[str]:
        """Identify top performing symbols based on confidence and sentiment"""
        if not summaries:
            return []
        
        # Score each symbol based on confidence and positive sentiment
        scored_symbols = []
        for summary in summaries:
            score = summary.confidence
            if summary.sentiment == "bullish":
                score += 20
            elif summary.sentiment == "bearish":
                score -= 10
            
            scored_symbols.append((summary.symbol, score))
        
        # Sort by score and return top performers
        scored_symbols.sort(key=lambda x: x[1], reverse=True)
        return [symbol for symbol, score in scored_symbols[:limit]]
    
    def identify_risk_alerts(self, summaries: List[SymbolSummary], risk_threshold: float = 70.0) -> List[str]:
        """Identify symbols with high risk scores"""
        risk_symbols = [s.symbol for s in summaries if s.risk_score > risk_threshold]
        return risk_symbols
    
    def generate_sector_analysis(self, summaries: List[SymbolSummary]) -> Dict[str, Any]:
        """Generate sector analysis based on symbol patterns"""
        if not summaries:
            return {}
        
        # Group by sector (simplified - in real implementation would use sector mapping)
        defi_symbols = [s for s in summaries if any(token in s.symbol.lower() for token in ["uni", "aave", "comp", "sushi"])]
        layer1_symbols = [s for s in summaries if any(token in s.symbol.lower() for token in ["btc", "eth", "sol", "ada"])]
        meme_symbols = [s for s in summaries if any(token in s.symbol.lower() for token in ["doge", "shib", "pepe"])]
        
        # Get symbols that don't fit into the above categories
        categorized_symbols = set()
        for symbols in [defi_symbols, layer1_symbols, meme_symbols]:
            categorized_symbols.update(s.symbol for s in symbols)
        other_symbols = [s for s in summaries if s.symbol not in categorized_symbols]
        
        sectors = {
            "defi": defi_symbols,
            "layer1": layer1_symbols,
            "meme": meme_symbols,
            "other": other_symbols
        }
        
        sector_analysis = {}
        for sector_name, sector_symbols in sectors.items():
            if sector_symbols:
                avg_confidence = sum(s.confidence for s in sector_symbols) / len(sector_symbols)
                bullish_count = sum(1 for s in sector_symbols if s.sentiment == "bullish")
                sector_analysis[sector_name] = {
                    "symbol_count": len(sector_symbols),
                    "avg_confidence": avg_confidence,
                    "bullish_percentage": (bullish_count / len(sector_symbols)) * 100,
                    "symbols": [s.symbol for s in sector_symbols]
                }
        
        return sector_analysis
    
    def generate_trading_opportunities(self, summaries: List[SymbolSummary]) -> List[Dict[str, Any]]:
        """Generate trading opportunities based on analysis"""
        opportunities = []
        
        for summary in summaries:
            if summary.confidence > 70 and summary.sentiment in ["bullish", "bearish"]:
                opportunity = {
                    "symbol": summary.symbol,
                    "sentiment": summary.sentiment,
                    "confidence": summary.confidence,
                    "risk_score": summary.risk_score,
                    "recommendation": summary.trading_recommendations,
                    "timeframe": "24h-1m",
                    "priority": "high" if summary.confidence > 85 else "medium"
                }
                opportunities.append(opportunity)
        
        # Sort by confidence and limit to top opportunities
        opportunities.sort(key=lambda x: x["confidence"], reverse=True)
        return opportunities[:10]
    
    def generate_risk_warnings(self, summaries: List[SymbolSummary]) -> List[str]:
        """Generate risk warnings based on analysis"""
        warnings = []
        
        high_risk_symbols = [s for s in summaries if s.risk_score > 80]
        if high_risk_symbols:
            symbols = [s.symbol for s in high_risk_symbols]
            warnings.append(f"High volatility detected in: {', '.join(symbols)}")
        
        low_confidence_symbols = [s for s in summaries if s.confidence < 30]
        if low_confidence_symbols:
            symbols = [s.symbol for s in low_confidence_symbols]
            warnings.append(f"Low confidence analysis for: {', '.join(symbols)}")
        
        extreme_sentiment = [s for s in summaries if s.sentiment in ["bullish", "bearish"] and s.confidence > 90]
        if len(extreme_sentiment) > len(summaries) * 0.7:
            warnings.append("Market showing extreme sentiment - potential reversal risk")
        
        return warnings
    
    def compose_professional_summary(self, master_summary: MasterSummary) -> str:
        """Compose a brilliant professional summary"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M UTC")
        
        summary = f"""# üéØ KingFisher Market Analysis Report
**Generated**: {timestamp}
**Analysis Period**: Last 24 Hours
**Total Symbols Analyzed**: {len(master_summary.trading_opportunities) + len(master_summary.risk_alert_symbols)}

## üìä Executive Summary

**Market Sentiment**: {master_summary.overall_sentiment.title()}
**Market Confidence**: {master_summary.market_confidence:.1f}%
**Market Trend**: {master_summary.market_trend.title()}

## üèÜ Top Performers
{chr(10).join([f"‚Ä¢ {symbol}" for symbol in master_summary.top_performers])}

## ‚ö†Ô∏è Risk Alerts
{chr(10).join([f"‚Ä¢ {symbol}" for symbol in master_summary.risk_alert_symbols]) if master_summary.risk_alert_symbols else "‚Ä¢ No high-risk symbols detected"}

## üíé Trading Opportunities
"""
        
        for opp in master_summary.trading_opportunities[:5]:
            summary += f"""
**{opp['symbol']}** ({opp['sentiment'].title()})
- Confidence: {opp['confidence']:.1f}%
- Risk Score: {opp['risk_score']:.1f}%
- Priority: {opp['priority'].title()}
- Recommendation: {opp['recommendation'][:100]}...
"""
        
        summary += f"""
## üé≠ Sector Analysis
"""
        
        for sector, data in master_summary.sector_analysis.items():
            summary += f"""
**{sector.upper()}** ({data['symbol_count']} symbols)
- Average Confidence: {data['avg_confidence']:.1f}%
- Bullish Percentage: {data['bullish_percentage']:.1f}%
- Top Symbols: {', '.join(data['symbols'][:3])}
"""
        
        if master_summary.risk_warnings:
            summary += f"""
## ‚ö†Ô∏è Risk Warnings
{chr(10).join([f"‚Ä¢ {warning}" for warning in master_summary.risk_warnings])}
"""
        
        summary += f"""
## üìà Market Outlook

Based on comprehensive analysis of {len(master_summary.trading_opportunities) + len(master_summary.risk_alert_symbols)} symbols, the market is showing a **{master_summary.overall_sentiment}** sentiment with **{master_summary.market_confidence:.1f}%** confidence.

**Key Insights:**
‚Ä¢ Market trend is **{master_summary.market_trend}**
‚Ä¢ {len(master_summary.trading_opportunities)} high-confidence trading opportunities identified
‚Ä¢ {len(master_summary.risk_alert_symbols)} symbols require careful monitoring
‚Ä¢ Sector rotation patterns indicate {master_summary.sector_analysis.get('defi', {}).get('bullish_percentage', 0):.1f}% DeFi bullishness

**Professional Recommendation:**
This analysis represents the most valuable data extracted from comprehensive technical analysis, liquidation mapping, and market microstructure analysis. All recommendations are based on professional-grade algorithms and real-time market data integration.

---
*Generated by KingFisher Master Summary Agent - Professional Trading Intelligence*
"""
        
        return summary
    
    async def generate_master_summary(self, hours_back: int = 24) -> MasterSummary:
        """Generate the master summary from all symbol analyses"""
        try:
            logger.info("üîç Starting Master Summary generation...")
            
            # Get all symbol records
            records = await self.get_all_symbol_records(hours_back)
            if not records:
                logger.warning("‚ö†Ô∏è No records found for master summary")
                return self._create_empty_master_summary()
            
            logger.info(f"üìä Processing {len(records)} symbol records...")
            
            # Extract summaries from records
            summaries = []
            for record in records:
                summary = self.extract_symbol_summary(record)
                if summary:
                    summaries.append(summary)
            
            if not summaries:
                logger.warning("‚ö†Ô∏è No valid summaries extracted")
                return self._create_empty_master_summary()
            
            logger.info(f"‚úÖ Extracted {len(summaries)} valid summaries")
            
            # Analyze market data
            market_trend = self.analyze_market_trend(summaries)
            top_performers = self.identify_top_performers(summaries)
            risk_alerts = self.identify_risk_alerts(summaries)
            sector_analysis = self.generate_sector_analysis(summaries)
            trading_opportunities = self.generate_trading_opportunities(summaries)
            risk_warnings = self.generate_risk_warnings(summaries)
            
            # Calculate overall metrics
            avg_confidence = sum(s.confidence for s in summaries) / len(summaries)
            bullish_count = sum(1 for s in summaries if s.sentiment == "bullish")
            overall_sentiment = "bullish" if bullish_count > len(summaries) * 0.6 else "bearish" if bullish_count < len(summaries) * 0.4 else "neutral"
            
            # Create master summary
            master_summary = MasterSummary(
                overall_sentiment=overall_sentiment,
                market_confidence=avg_confidence,
                top_performers=top_performers,
                risk_alert_symbols=risk_alerts,
                market_trend=market_trend,
                sector_analysis=sector_analysis,
                trading_opportunities=trading_opportunities,
                risk_warnings=risk_warnings,
                professional_summary="",  # Will be generated below
                executive_summary=f"Market is {overall_sentiment} with {avg_confidence:.1f}% confidence. {len(trading_opportunities)} opportunities identified.",
                timestamp=datetime.now().isoformat()
            )
            
            # Generate professional summary
            master_summary.professional_summary = self.compose_professional_summary(master_summary)
            
            logger.info("‚úÖ Master Summary generated successfully")
            return master_summary
            
        except Exception as e:
            logger.error(f"‚ùå Error generating master summary: {str(e)}")
            return self._create_empty_master_summary()
    
    def _create_empty_master_summary(self) -> MasterSummary:
        """Create an empty master summary when no data is available"""
        return MasterSummary(
            overall_sentiment="neutral",
            market_confidence=0.0,
            top_performers=[],
            risk_alert_symbols=[],
            market_trend="insufficient_data",
            sector_analysis={},
            trading_opportunities=[],
            risk_warnings=["No data available for analysis"],
            professional_summary="No data available for master summary generation.",
            executive_summary="Insufficient data for analysis.",
            timestamp=datetime.now().isoformat()
        )
    
    async def test_master_summary(self) -> Dict[str, Any]:
        """Test the master summary generation"""
        try:
            logger.info("üß™ Testing Master Summary Agent...")
            
            master_summary = await self.generate_master_summary(hours_back=24)
            
            test_result = {
                "status": "success",
                "timestamp": datetime.now().isoformat(),
                "summary_stats": {
                    "overall_sentiment": master_summary.overall_sentiment,
                    "market_confidence": master_summary.market_confidence,
                    "top_performers_count": len(master_summary.top_performers),
                    "risk_alerts_count": len(master_summary.risk_alert_symbols),
                    "trading_opportunities_count": len(master_summary.trading_opportunities),
                    "sector_analysis_count": len(master_summary.sector_analysis),
                    "risk_warnings_count": len(master_summary.risk_warnings)
                },
                "executive_summary": master_summary.executive_summary,
                "professional_summary_length": len(master_summary.professional_summary)
            }
            
            logger.info("‚úÖ Master Summary test completed successfully")
            return test_result
            
        except Exception as e:
            logger.error(f"‚ùå Master Summary test failed: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            } 